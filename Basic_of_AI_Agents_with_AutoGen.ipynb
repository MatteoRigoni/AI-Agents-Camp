{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMciMORAauGo2zbLvlk+aTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoRigoni/AI-Agent-workshop/blob/master/Basic_of_AI_Agents_with_AutoGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sefnQoEuTfsM",
        "outputId": "db159f57-d721-4f22-cab3-37a0d74e3ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyautogen in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Collecting autogen\n",
            "  Downloading autogen-0.9.7-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: autogen-agentchat>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.7.2)\n",
            "Collecting ag2==0.9.7 (from autogen)\n",
            "  Downloading ag2-0.9.7-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (4.10.0)\n",
            "Collecting asyncer==0.0.8 (from ag2==0.9.7->autogen)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from ag2==0.9.7->autogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from ag2==0.9.7->autogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (2.11.7)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (0.11.0)\n",
            "Requirement already satisfied: autogen-core==0.7.2 in /usr/local/lib/python3.11/dist-packages (from autogen-agentchat>=0.6.4->pyautogen) (0.7.2)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (1.36.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (11.3.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (5.29.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.7->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.7->autogen) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.7->autogen) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.7->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.7->autogen) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.7->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.7->autogen) (2.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.7->autogen) (2024.11.6)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.34.1->autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (8.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2==0.9.7->autogen) (3.4.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (3.23.0)\n",
            "Downloading autogen-0.9.7-py3-none-any.whl (13 kB)\n",
            "Downloading ag2-0.9.7-py3-none-any.whl (860 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m860.4/860.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache, docker, asyncer, ag2, autogen\n",
            "Successfully installed ag2-0.9.7 asyncer-0.0.8 autogen-0.9.7 diskcache-5.6.3 docker-7.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyautogen python-dotenv autogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzDWyVQ0TjVs",
        "outputId": "251925ff-0169-446b-b67f-700b5c314361"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\"model\": \"gpt-4o-mini\"}"
      ],
      "metadata": {
        "id": "P5bJPixVTsxx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define single Agent"
      ],
      "metadata": {
        "id": "baXJiNR0T_12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent"
      ],
      "metadata": {
        "id": "3QfV68YTTwrL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ConversableAgent(\n",
        "    name=\"chatbot\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")"
      ],
      "metadata": {
        "id": "343g9tRcUFrF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"Tell me a joke\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLKpN98MUQ-s",
        "outputId": "1977f559-9d65-4647-8e85-f42f3d0b835b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't scientists trust atoms? \n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation between two Conversable Agents"
      ],
      "metadata": {
        "id": "shCqnDmoVKW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\"Your name is Cathy and you are a stand-up comedian.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\n",
        "      \"Your name is Cathy and you are a stand-up comedian.\"\n",
        "      \"Start the next joke from the punchline of the previous joke.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")"
      ],
      "metadata": {
        "id": "D1mxMkjIUxob"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling!\",\n",
        "    max_turns=2,\n",
        "    #is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"]\n",
        "    summary_method = \"reflection_with_llm\",\n",
        "    summary_prompt=\"Summarize the conversation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vCckhIXVpp4",
        "outputId": "f5048e3f-b096-478f-c898-05f16d7635d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey Joe! Alright, let’s roll! You know, they say laughter is the best medicine. But if that's true, I must not have health insurance because my jokes are the only thing keeping me from going to the doctor! How about you? What’s your go-to joke?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Well, they say laughter is indeed the best medicine, but if that’s the case, I must be a pharmacist because I’m handing out these jokes like candy! You know what I say, if you're ever feeling down, just remember: every time you laugh, a diet soda gets its wings!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Haha, Joe! That’s fantastic! You're handing out jokes like a pharmacist, huh? I love it! You must be the only one making people laugh and avoiding the “side effects.” And that diet soda thing? I can just see some little can of cola soaring through the sky, screaming, “I’m sweet enough already!” Keep ‘em coming! What else you got?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (ceaa57ad-710a-47d2-8ccf-0c0331ca39fe): Maximum turns (2) reached\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(chat_result.chat_history)\n",
        "pprint.pprint(chat_result.cost)\n",
        "pprint.pprint(chat_result.summary) #summary based on above settings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCYWGdOYV4MX",
        "outputId": "8dcf7868-c6c2-4cae-8e80-f27e9eb33698"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling!\",\n",
            "  'name': 'joe',\n",
            "  'role': 'assistant'},\n",
            " {'content': 'Hey Joe! Alright, let’s roll! You know, they say laughter is the '\n",
            "             \"best medicine. But if that's true, I must not have health \"\n",
            "             'insurance because my jokes are the only thing keeping me from '\n",
            "             'going to the doctor! How about you? What’s your go-to joke?',\n",
            "  'name': 'cathy',\n",
            "  'role': 'user'},\n",
            " {'content': 'Well, they say laughter is indeed the best medicine, but if '\n",
            "             'that’s the case, I must be a pharmacist because I’m handing out '\n",
            "             \"these jokes like candy! You know what I say, if you're ever \"\n",
            "             'feeling down, just remember: every time you laugh, a diet soda '\n",
            "             'gets its wings!',\n",
            "  'name': 'joe',\n",
            "  'role': 'assistant'},\n",
            " {'content': \"Haha, Joe! That’s fantastic! You're handing out jokes like a \"\n",
            "             'pharmacist, huh? I love it! You must be the only one making '\n",
            "             'people laugh and avoiding the “side effects.” And that diet soda '\n",
            "             'thing? I can just see some little can of cola soaring through '\n",
            "             'the sky, screaming, “I’m sweet enough already!” Keep ‘em coming! '\n",
            "             'What else you got?',\n",
            "  'name': 'cathy',\n",
            "  'role': 'user'}]\n",
            "{'usage_excluding_cached_inference': {'gpt-4o-mini-2024-07-18': {'completion_tokens': 468,\n",
            "                                                                 'cost': 0.00037814999999999995,\n",
            "                                                                 'prompt_tokens': 649,\n",
            "                                                                 'total_tokens': 1117},\n",
            "                                      'total_cost': 0.00037814999999999995},\n",
            " 'usage_including_cached_inference': {'gpt-4o-mini-2024-07-18': {'completion_tokens': 468,\n",
            "                                                                 'cost': 0.00037814999999999995,\n",
            "                                                                 'prompt_tokens': 649,\n",
            "                                                                 'total_tokens': 1117},\n",
            "                                      'total_cost': 0.00037814999999999995}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using of tools"
      ],
      "metadata": {
        "id": "bwPUWB7OW6kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Literal\n",
        "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
        "\n",
        "def calculator(a:int, b:int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
        "  \"\"\"A simple calculator tool\"\"\"\n",
        "  if operator == \"+\":\n",
        "      return a + b\n",
        "  elif operator == \"-\":\n",
        "      return a - b\n",
        "  else:\n",
        "    raise ValueError(\"Invalid operator\")"
      ],
      "metadata": {
        "id": "UL1w4_C5WEMw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_expert_agent = ConversableAgent(\n",
        "    name=\"MathExpert\",\n",
        "    system_message=\n",
        "      \"You are very good at math \"\n",
        "      \"and you help users to solve thei math problems.\",\n",
        "    llm_config=llm_config,\n",
        "    function_map={\"calculator\": calculator},\n",
        "    human_input_mode=\"NEVER\"\n",
        ")"
      ],
      "metadata": {
        "id": "Th2TWxFvXmC2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_expert_agent.register_for_llm(name=\"calculator\", description=\"A tool to make math operations\")(calculator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLNbL4oIX5nr",
        "outputId": "11337a23-c408-4ac3-e8d6-d83a3311bc70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogen.tools.tool.Tool at 0x7fb7855ea290>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "reply = math_expert_agent.generate_reply(\n",
        "    messages=[{\"content\":\"What is 2+2?\", \"role\" : \"user\"}]\n",
        ")"
      ],
      "metadata": {
        "id": "D2G_IeNiYBSW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a team of Agents (sketch)\n",
        "\n",
        "**UserProxy**: to allow the user to comment on the report and ask the writer to refine it\n",
        "\n",
        "**Planner**: to determine relevant info needed to complete the task\n",
        "\n",
        "**Engineer**: to write code using the defined plan by the planner\n",
        "\n",
        "**Executor**: to execute the code written by the engineer\n",
        "\n",
        "**Writer**: to write report"
      ],
      "metadata": {
        "id": "65pviLs7Ym3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen"
      ],
      "metadata": {
        "id": "U-G08AvnYsm8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_proxy = autogen.ConversableAgent(\n",
        "    name=\"user_proxy\",\n",
        "    system_message=\"Give the task and send instrctions to writer to refine the blog post\",\n",
        "    code_execution_config=False,\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"ALWAYS\"\n",
        ")"
      ],
      "metadata": {
        "id": "VmrHygO9YRS0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "zAH_zYpNZ8zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouptchat = autogen.GroupChat(\n",
        "    agents=[user_proxy],\n",
        "    messages=[],\n",
        "    max_round=10\n",
        ")"
      ],
      "metadata": {
        "id": "irKUdP1HZ-Jq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to determinate which agent should be involved\n",
        "manager = autogen.GroupChatManager(\n",
        "    groupchat=grouptchat,\n",
        "    llm_config=llm_config,\n",
        ")"
      ],
      "metadata": {
        "id": "h6_mIN-UaGPu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"<Define a task>\"\n",
        "\n",
        "groupchat_result = user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=task\n",
        ")"
      ],
      "metadata": {
        "id": "NYWvb0YoaM_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4pa717UabIx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}