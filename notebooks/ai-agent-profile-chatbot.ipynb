{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf972e87",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e3cb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Imports & config\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpypdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# Imports & config\n",
    "# Ensure required libraries are installed\n",
    "!pip install python-dotenv openai pypdf2 gradio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9c921",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRY_RUN = True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {OPENAI_API_KEY}' if OPENAI_API_KEY else '',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd36d1",
   "metadata": {},
   "source": [
    "## Prompts and Resources loading\n",
    "Load from disk a CV in pdf format and a presentation letter as text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada35036",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "reader = PdfReader(\"assets/me/CV.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "print(linkedin)\n",
    "\n",
    "with open(\"assets/me/about.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Matteo Rigoni\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9474a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeeeaa8",
   "metadata": {},
   "source": [
    "## Minimal OpenAI‑compatible client + helpers\n",
    "- `chat(messages)` calls the Chat Completions API or returns **mocked** JSON when `DRY_RUN=True`.\n",
    "- `jparse(s)` safely parses JSON (with a small fallback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3ccda5",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "def jparse(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        s2 = s.strip().strip('`\\n ')\n",
    "        first = s2.find('{'); last = s2.rfind('}')\n",
    "        if first != -1 and last != -1:\n",
    "            return json.loads(s2[first:last+1])\n",
    "        raise\n",
    "\n",
    "def _mock_response_for(prompt: str) -> str:\n",
    "    # Heuristic mock based on which prompt it is\n",
    "    if 'business area' in prompt and 'Return JSON with' in prompt and 'business_area' in prompt:\n",
    "        return json.dumps({\n",
    "            'business_area': 'Property Management (SMB)',\n",
    "            'why_promising': 'Fragmented operations, thin margins, and repetitive workflows enable agents to coordinate vendors and tenants end‑to‑end.'\n",
    "        })\n",
    "    if 'identify one high‑value pain‑point' in prompt:\n",
    "        return json.dumps({\n",
    "            'pain_point': 'Coordinating maintenance across units: triage, scheduling, and follow‑ups',\n",
    "            'who_is_affected': 'Property managers and tenants in buildings with 50–500 units',\n",
    "            'current_workarounds': 'Shared inboxes, spreadsheets, and phone tag with vendors',\n",
    "            'why_hard': 'Unstructured requests, multi‑party constraints in scheduling, poor status visibility.'\n",
    "        })\n",
    "    if 'Propose an Agentic AI solution' in prompt:\n",
    "        return json.dumps({\n",
    "            'solution_name': 'FixFlow Agent Mesh',\n",
    "            'agent_roles': ['Triage Agent','Planner','Vendor Liaison','QA/Evaluator'],\n",
    "            'data_sources': ['Tenant portal messages','Calendar APIs','Vendor CRM','Photos/Videos'],\n",
    "            'key_actions': ['Parse issue','Quote ETA','Auto‑schedule vendor','Confirm completion'],\n",
    "            'success_metrics': ['Time‑to‑schedule','First‑visit fix %','CSAT'],\n",
    "            'risks': ['Hallucinated scheduling','Vendor no‑shows','Edge cases'],\n",
    "            'quick_prototype': [\n",
    "                'Webhook intake from tenant form',\n",
    "                'LLM triage → category+priority',\n",
    "                'Heuristic + calendar API scheduling',\n",
    "                'Email/SMS notifications',\n",
    "                'Simple dashboard for overrides',\n",
    "                'Audit log and trace capture'\n",
    "            ]\n",
    "        })\n",
    "    # default fallthrough\n",
    "    return json.dumps({'note': 'mock'})\n",
    "\n",
    "def chat(messages):\n",
    "    if DRY_RUN:\n",
    "        # Return a plausible mock based on the last user message\n",
    "        last_user = next((m['content'] for m in reversed(messages) if m['role']=='user'), '')\n",
    "        return _mock_response_for(last_user)\n",
    "    url = f\"{OPENAI_BASE_URL}/chat/completions\"\n",
    "    resp = requests.post(\n",
    "        url,\n",
    "        headers=HEADERS,\n",
    "        json={\n",
    "            'model': OPENAI_MODEL,\n",
    "            'messages': messages,\n",
    "            'temperature': 0.7,\n",
    "        },\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4863b4",
   "metadata": {},
   "source": [
    "## Run the three‑call flow\n",
    "This cell performs the full chain and writes `trace.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591faff5",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Result ===\n",
      "Business Area: Property Management (SMB)\n",
      "Pain‑Point   : Coordinating maintenance across units: triage, scheduling, and follow‑ups\n",
      "Solution     : FixFlow Agent Mesh\n"
     ]
    }
   ],
   "source": [
    "def run_chain():\n",
    "    trace = {'calls': [], 'created_at': datetime.utcnow().isoformat() + 'Z'}\n",
    "    messages = [SYSTEM]\n",
    "\n",
    "    # 1) Business area\n",
    "    messages.append({'role': 'user', 'content': PROMPTS['area']})\n",
    "    raw1 = chat(messages)\n",
    "    out1 = jparse(raw1)\n",
    "    trace['calls'].append({'step': 1, 'prompt': PROMPTS['area'], 'response': out1})\n",
    "\n",
    "    # 2) Pain‑point\n",
    "    p2 = PROMPTS['pain'].replace('{{business_area}}', out1['business_area'])\n",
    "    messages.append({'role': 'user', 'content': p2})\n",
    "    raw2 = chat(messages)\n",
    "    out2 = jparse(raw2)\n",
    "    trace['calls'].append({'step': 2, 'prompt': p2, 'response': out2})\n",
    "\n",
    "    # 3) Agentic solution\n",
    "    p3 = PROMPTS['solution'] \\\n",
    "        .replace('{{business_area}}', out1['business_area']) \\\n",
    "        .replace('{{pain_point}}', out2['pain_point'])\n",
    "    messages.append({'role': 'user', 'content': p3})\n",
    "    raw3 = chat(messages)\n",
    "    out3 = jparse(raw3)\n",
    "    trace['calls'].append({'step': 3, 'prompt': p3, 'response': out3})\n",
    "\n",
    "    # Save trace\n",
    "    with open('trace.json', 'w') as f:\n",
    "        json.dump(trace, f, indent=2)\n",
    "\n",
    "    return out1, out2, out3\n",
    "\n",
    "area, pain, solution = run_chain()\n",
    "print('=== Result ===')\n",
    "print('Business Area:', area.get('business_area'))\n",
    "print('Pain‑Point   :', pain.get('pain_point'))\n",
    "print('Solution     :', solution.get('solution_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c74f7",
   "metadata": {},
   "source": [
    "## Inspect the trace.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b84e9a",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"calls\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"prompt\": \"Task: Pick one business area that\\u2019s promising for an Agentic AI opportunity.\\nReturn JSON with:\\n- business_area: string\\n- why_promising: string (\\u2264 2 sentences)\\nConstraints: Keep it under 80 words total.\",\n",
      "      \"response\": {\n",
      "        \"business_area\": \"Property Management (SMB)\",\n",
      "        \"why_promising\": \"Fragmented operations, thin margins, and repetitive workflows enable agents to coordinate vendors and tenants end\\u2011to\\u2011end.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"prompt\": \"Task: In the business area \\\"Property Management (SMB)\\\", identify one high\\u2011value pain\\u2011point.\\nReturn JSON with:\\n- pain_point: string\\n- who_is_affected: string\\n- current_workarounds: string\\n- why_hard: string\\nConstraints: Keep it under 120 words total.\",\n",
      "      \"response\": {\n",
      "        \"pain_point\": \"Coordinating maintenance across units: triage, scheduling, and follow\\u2011ups\",\n",
      "        \"who_is_affected\": \"Property managers and tenants in buildings with 50\\u2013500 units\",\n",
      "        \"current_workarounds\": \"Shared inboxes, spreadsheets, and phone tag with vendors\",\n",
      "        \"why_hard\": \"Unstructured requests, multi\\u2011party constraints in scheduling, poor status visibility.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"prompt\": \"Task: Propose an Agentic AI solution for the pain-point \\\"Coordinating maintenance across units: triage, scheduling, and follow\\u2011ups\\\" in the area \\\"Property Management (SMB)\\\".\\nReturn JSON with:\\n- solution_name: string\\n- agent_roles: string[]\\n- data_sources: string[]\\n- key_actions: string[]\\n- success_metrics: string[]\\n- risks: string[]\\n- quick_prototype: string[]\\nConstraints: Keep it under 180 words total.\",\n",
      "      \"response\": {\n",
      "        \"solution_name\": \"FixFlow Agent Mesh\",\n",
      "        \"agent_roles\": [\n",
      "          \"Triage Agent\",\n",
      "          \"Planner\",\n",
      "          \"Vendor Liaison\",\n",
      "          \"QA/Evaluator\"\n",
      "        ],\n",
      "        \"data_sources\": [\n",
      "          \"Tenant portal messages\",\n",
      "          \"Calendar APIs\",\n",
      "          \"Vendor CRM\",\n",
      "          \"Photos/Videos\"\n",
      "        ],\n",
      "        \"key_actions\": [\n",
      "          \"Parse issue\",\n",
      "          \"Quote ETA\",\n",
      "          \"Auto\\u2011schedule vendor\",\n",
      "          \"Confirm completion\"\n",
      "        ],\n",
      "        \"success_metrics\": [\n",
      "          \"Time\\u2011to\\u2011schedule\",\n",
      "          \"First\\u2011visit fix %\",\n",
      "          \"CSAT\"\n",
      "        ],\n",
      "        \"risks\": [\n",
      "          \"Hallucinated scheduling\",\n",
      "          \"Vendor no\\u2011shows\",\n",
      "          \"Edge cases\"\n",
      "        ],\n",
      "        \"quick_prototype\": [\n",
      "          \"Webhook intake from tenant form\",\n",
      "          \"LLM triage \\u2192 category+priority\",\n",
      "          \"Heuristic + calendar API scheduling\",\n",
      "          \"Email/SMS notifications\",\n",
      "          \"Simple dashboard for overrides\",\n",
      "          \"Audit log and trace capture\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created_at\": \"2025-09-08T19:34:42.971203Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('trace.json') as f:\n",
    "    trace = json.load(f)\n",
    "print(json.dumps(trace, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
