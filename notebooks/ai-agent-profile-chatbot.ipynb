{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf972e87",
   "metadata": {},
   "source": [
    "# AI Agent Profile Chatbot\n",
    "\n",
    "This notebook creates an AI chatbot using OpenAI's GPT model to answer questions about a professional profile. It uses a system prompt with the user's background and LinkedIn data and is deployed with Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86609bce",
   "metadata": {},
   "source": [
    "## Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189e3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\source\\AI-Agents-Camp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f9c921",
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {OPENAI_API_KEY}' if OPENAI_API_KEY else '',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd36d1",
   "metadata": {},
   "source": [
    "## Prompts and Resources loading\n",
    "Load from disk a CV in pdf format and a presentation letter as text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0497e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../assets/me/CV.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"../assets/me/about.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Matteo Rigoni\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9474a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Matteo Rigoni. You are answering questions on Matteo Rigoni's website, particularly questions related to Matteo Rigoni's career, background, skills and experience. Your responsibility is to represent Matteo Rigoni for interactions on the website as faithfully as possible. You are given a summary of Matteo Rigoni's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nSono uno sviluppatore full-stack, focalizzato sul backend in .NET e Azure. Lavoro su progetti enterprise — per lo più cloud, ma non solo — con un approccio pragmatico: soluzioni solide, senza complessità superflue.\\n\\nConsidero lo studio un requisito chiave di questo lavoro: l’apprendimento continuo si traduce in strumenti e pratiche che arricchiscono il mio bagaglio professionale.\\n\\nL’AI è ormai un alleato fisso nel mio flusso di lavoro: vibe coding dalla progettazione allo sviluppo, ma applicato con metodo e giudizio.\\n\\n## LinkedIn Profile:\\nMatteo Rigoni \\nSenior Full-Stack Developer | Cloud & AI-Oriented | Microsoft Certiﬁed \\nSenior Developer con 10+ anni di esperienza su stack Microsoft (.NET, C#, Azure), specializzato in\\narchitetture a microservizi e soluzioni cloud-native. Lavoro su progetti full-stack orientati a scalabilità,\\nqualità e integrazione continua. In parallelo mi formo su AI engineering (LLM, Azure OpenAI, RAG) e\\nanalisi dati. Cerco ruoli con impatto tecnico e possibilità di crescita. \\nmatteo.rigoni2@gmail.com \\n3669793171 \\nBellaria Igea Marina, Italy \\nlinkedin.com/in/matteo-rigoni-63440b114 \\nfacebook.com/matteo.rigoni.39 \\ngithub.com/MatteoRigoni \\nWORK EXPERIENCE \\nSviluppatore e Analista \\nBluenext \\n06/2016 - Present\\n, \\n \\nResponsabile tecnico di moduli chiave (portali di servizi,\\nfatturazione elettronica, conservazione digitale). \\nProgettazione e sviluppo di piattaforma cloud per servizi\\nﬁscali/documentali, usata da migliaia di aziende con forte\\nintegrazione con enti come l'Agenzia delle Entrate \\nConduzione di attività di refactoring, miglioramento\\nperformance, code review. \\nSviluppatore \\nItalstudio \\n06/2012 - 06/2016\\n, \\n \\nSviluppo e manutenzione di soluzioni per la gestione dei ﬁle\\ntelematici AdE. \\nIntegrazione dati da software house esterne \\nSviluppo di tool interni per pianiﬁcazione progetti e gestione\\nteam \\nSviluppatore stagista \\nESA Software \\n09/2011 - 12/2011\\n, \\n \\nScrittura di test automatici (unit & integration) \\nEDUCATION \\nLaurea in Scienze e Tecnologie Informatiche \\nAlma Mater Studiorum di Bologna \\n10/2008 - 02/2012\\n, \\n \\n105 / 110 \\nAlgoritmi e strutture dati \\nArchitetture basi di dati \\nReti di calcolatori \\nMatematica e statistica \\nDiploma maturità scientiﬁca \\nPNI (Matematica e ﬁsica) \\n09/2003 - 07/2008\\n, \\n \\nViserba (RN) \\nSKILLS \\nC#, .NET, Blazor (WASM/Server) \\nArchitetture & Design Cloud \\nDatabase SQL, orm EF/Dapper \\nData Science, AI Engeneering \\nAngular, NodeJS, HTML+CSS \\nGitHub, Agile/Scrum, CI/CD \\nDevOps, Docker, Kubernetes \\nPowerBI \\nACHIEVEMENTS AND COURSES \\nMaster Data Science - Profession AI\\n (09/2024 - Present)\\n \\nAngular Developer - Intermediate\\n (04/2024 - Present)\\n \\nAZ-305: Microsoft Solution Architects\\n (11/2023 - Present)\\n \\nAZ-400: Microsoft DevOps Engeneer Expert\\n (12/2023 - Present)\\n \\nArchitettura del Software\\n (07/2022 - 07/2022)\\n \\nAttestato frequenza corso OverNet \\nSecure Coding\\n (10/2022 - 10/2022)\\n \\nAttestato frequenza corso OverNet \\nLANGUAGES \\nInglese \\nProfessional Working Proﬁciency \\nFrancese \\nElementary Proﬁciency \\nINTERESTS \\nSport \\nTecnologia \\nFotograﬁa \\nViaggi \\nAchievements/Tasks \\nAchievements/Tasks \\nAchievements/Tasks \\nCourses \\n\\nWith this context, please chat with the user, always staying in character as Matteo Rigoni.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3082e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeeeaa8",
   "metadata": {},
   "source": [
    "## Test with gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f3ccda5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeeebf5",
   "metadata": {},
   "source": [
    "## Evaluation of Agent's output\n",
    "\n",
    "Guardrail on answer provided by LLM, if not acceptable, run again.\n",
    "\n",
    "Suggested use of a different kind of LLM (as Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26ca8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b322278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75fb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    resp = openai.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)},\n",
    "        ],\n",
    "        text_format=Evaluation,  \n",
    "    )\n",
    "    return resp.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9122ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40cce3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_evaluation(message, history):    \n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85c375d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518acd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
