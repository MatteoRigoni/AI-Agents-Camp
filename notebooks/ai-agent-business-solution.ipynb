{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0b6a5a",
   "metadata": {},
   "source": [
    "# Ai Agent Business Solution\n",
    "\n",
    "This curated notebook demonstrates ai agent business solution.\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Tutorial\n",
    "3. Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830dd4d9",
   "metadata": {},
   "source": [
    "# Agentic Solution for Business Pain Points\n",
    "\n",
    "\n",
    "*What this notebook does*\n",
    "1. Calls an LLM to pick a **business area** worth exploring.\n",
    "2. Calls an LLM to surface a sharp **pain‑point** in that area.\n",
    "3. Calls an LLM to propose an **Agentic AI** solution (roles, tools, loops, risks, quick prototype).\n",
    "4. Saves a full **JSON trace** of prompts and responses to `trace.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c928629",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "# Imports & config\n",
    "import os, json, textwrap\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "\n",
    "# Toggle mock mode automatically if no key is present\n",
    "DRY_RUN = os.getenv('DRY_RUN', '').lower() in {'1','true','yes'} or not bool(OPENAI_API_KEY)\n",
    "print('DRY_RUN =', DRY_RUN)\n",
    "\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {OPENAI_API_KEY}' if OPENAI_API_KEY else '',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd36d1",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "All calls share the same **system prompt**. User prompts are injected with prior outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c415a",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "SYSTEM = {\n",
    "    'role': 'system',\n",
    "    'content': (\n",
    "        'You are a concise, structured strategist. '\n",
    "        'Always reply as strict JSON only. No prose, no backticks, no explanations. '\n",
    "        'If lists are needed, use arrays of short strings.'\n",
    "    ),\n",
    "}\n",
    "\n",
    "PROMPTS = {\n",
    "    'area': (\n",
    "        \"Task: Pick one business area that’s promising for an Agentic AI opportunity.\\n\"\n",
    "        \"Return JSON with:\\n- business_area: string\\n- why_promising: string (≤ 2 sentences)\\n\"\n",
    "        \"Constraints: Keep it under 80 words total.\"\n",
    "    ),\n",
    "    'pain': (\n",
    "        \"Task: In the business area \\\"{{business_area}}\\\", identify one high‑value pain‑point.\\n\"\n",
    "        \"Return JSON with:\\n- pain_point: string\\n- who_is_affected: string\\n- current_workarounds: string\\n- why_hard: string\\n\"\n",
    "        \"Constraints: Keep it under 120 words total.\"\n",
    "    ),\n",
    "    'solution': (\n",
    "        \"Task: Propose an Agentic AI solution for the pain-point \\\"{{pain_point}}\\\" in the area \\\"{{business_area}}\\\".\\n\"\n",
    "        \"Return JSON with:\\n- solution_name: string\\n- agent_roles: string[]\\n- data_sources: string[]\\n- key_actions: string[]\\n- success_metrics: string[]\\n- risks: string[]\\n- quick_prototype: string[]\\n\"\n",
    "        \"Constraints: Keep it under 180 words total.\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df645ded",
   "metadata": {},
   "source": [
    "## Minimal OpenAI‑compatible client + helpers\n",
    "- `chat(messages)` calls the Chat Completions API or returns **mocked** JSON when `DRY_RUN=True`.\n",
    "- `jparse(s)` safely parses JSON (with a small fallback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75093e",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "def jparse(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        s2 = s.strip().strip('`\\n ')\n",
    "        first = s2.find('{'); last = s2.rfind('}')\n",
    "        if first != -1 and last != -1:\n",
    "            return json.loads(s2[first:last+1])\n",
    "        raise\n",
    "\n",
    "def _mock_response_for(prompt: str) -> str:\n",
    "    # Heuristic mock based on which prompt it is\n",
    "    if 'business area' in prompt and 'Return JSON with' in prompt and 'business_area' in prompt:\n",
    "        return json.dumps({\n",
    "            'business_area': 'Property Management (SMB)',\n",
    "            'why_promising': 'Fragmented operations, thin margins, and repetitive workflows enable agents to coordinate vendors and tenants end‑to‑end.'\n",
    "        })\n",
    "    if 'identify one high‑value pain‑point' in prompt:\n",
    "        return json.dumps({\n",
    "            'pain_point': 'Coordinating maintenance across units: triage, scheduling, and follow‑ups',\n",
    "            'who_is_affected': 'Property managers and tenants in buildings with 50–500 units',\n",
    "            'current_workarounds': 'Shared inboxes, spreadsheets, and phone tag with vendors',\n",
    "            'why_hard': 'Unstructured requests, multi‑party constraints in scheduling, poor status visibility.'\n",
    "        })\n",
    "    if 'Propose an Agentic AI solution' in prompt:\n",
    "        return json.dumps({\n",
    "            'solution_name': 'FixFlow Agent Mesh',\n",
    "            'agent_roles': ['Triage Agent','Planner','Vendor Liaison','QA/Evaluator'],\n",
    "            'data_sources': ['Tenant portal messages','Calendar APIs','Vendor CRM','Photos/Videos'],\n",
    "            'key_actions': ['Parse issue','Quote ETA','Auto‑schedule vendor','Confirm completion'],\n",
    "            'success_metrics': ['Time‑to‑schedule','First‑visit fix %','CSAT'],\n",
    "            'risks': ['Hallucinated scheduling','Vendor no‑shows','Edge cases'],\n",
    "            'quick_prototype': [\n",
    "                'Webhook intake from tenant form',\n",
    "                'LLM triage → category+priority',\n",
    "                'Heuristic + calendar API scheduling',\n",
    "                'Email/SMS notifications',\n",
    "                'Simple dashboard for overrides',\n",
    "                'Audit log and trace capture'\n",
    "            ]\n",
    "        })\n",
    "    # default fallthrough\n",
    "    return json.dumps({'note': 'mock'})\n",
    "\n",
    "def chat(messages):\n",
    "    if DRY_RUN:\n",
    "        # Return a plausible mock based on the last user message\n",
    "        last_user = next((m['content'] for m in reversed(messages) if m['role']=='user'), '')\n",
    "        return _mock_response_for(last_user)\n",
    "    url = f\"{OPENAI_BASE_URL}/chat/completions\"\n",
    "    resp = requests.post(\n",
    "        url,\n",
    "        headers=HEADERS,\n",
    "        json={\n",
    "            'model': OPENAI_MODEL,\n",
    "            'messages': messages,\n",
    "            'temperature': 0.7,\n",
    "        },\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3098c090",
   "metadata": {},
   "source": [
    "## Run the three‑call flow\n",
    "This cell performs the full chain and writes `trace.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9c6fe",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "def run_chain():\n",
    "    trace = {'calls': [], 'created_at': datetime.utcnow().isoformat() + 'Z'}\n",
    "    messages = [SYSTEM]\n",
    "\n",
    "    # 1) Business area\n",
    "    messages.append({'role': 'user', 'content': PROMPTS['area']})\n",
    "    raw1 = chat(messages)\n",
    "    out1 = jparse(raw1)\n",
    "    trace['calls'].append({'step': 1, 'prompt': PROMPTS['area'], 'response': out1})\n",
    "\n",
    "    # 2) Pain‑point\n",
    "    p2 = PROMPTS['pain'].replace('{{business_area}}', out1['business_area'])\n",
    "    messages.append({'role': 'user', 'content': p2})\n",
    "    raw2 = chat(messages)\n",
    "    out2 = jparse(raw2)\n",
    "    trace['calls'].append({'step': 2, 'prompt': p2, 'response': out2})\n",
    "\n",
    "    # 3) Agentic solution\n",
    "    p3 = PROMPTS['solution'] \\\n",
    "        .replace('{{business_area}}', out1['business_area']) \\\n",
    "        .replace('{{pain_point}}', out2['pain_point'])\n",
    "    messages.append({'role': 'user', 'content': p3})\n",
    "    raw3 = chat(messages)\n",
    "    out3 = jparse(raw3)\n",
    "    trace['calls'].append({'step': 3, 'prompt': p3, 'response': out3})\n",
    "\n",
    "    # Save trace\n",
    "    with open('trace.json', 'w') as f:\n",
    "        json.dump(trace, f, indent=2)\n",
    "\n",
    "    return out1, out2, out3\n",
    "\n",
    "area, pain, solution = run_chain()\n",
    "print('=== Result ===')\n",
    "print('Business Area:', area.get('business_area'))\n",
    "print('Pain‑Point   :', pain.get('pain_point'))\n",
    "print('Solution     :', solution.get('solution_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417819c",
   "metadata": {},
   "source": [
    "## Inspect the trace.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bb49a",
   "metadata": {
    "execution": {
     "timeout": 120000
    }
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "with open('trace.json') as f:\n",
    "    trace = json.load(f)\n",
    "print(json.dumps(trace, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
