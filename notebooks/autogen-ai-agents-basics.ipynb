{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents Basics with AutoGen\n",
    "\n",
    "Introduces core AutoGen concepts for orchestrating conversations between autonomous agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sefnQoEuTfsM",
    "outputId": "db159f57-d721-4f22-cab3-37a0d74e3ac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
      "Collecting autogen\n",
      "  Downloading autogen-0.9.7-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: autogen-agentchat>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.7.2)\n",
      "Collecting ag2==0.9.7 (from autogen)\n",
      "  Downloading ag2-0.9.7-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (4.10.0)\n",
      "Collecting asyncer==0.0.8 (from ag2==0.9.7->autogen)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting diskcache (from ag2==0.9.7->autogen)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docker (from ag2==0.9.7->autogen)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (2.11.7)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.7->autogen) (0.11.0)\n",
      "Requirement already satisfied: autogen-core==0.7.2 in /usr/local/lib/python3.11/dist-packages (from autogen-agentchat>=0.6.4->pyautogen) (0.7.2)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (1.36.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (11.3.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (5.29.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.7->autogen) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.7->autogen) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.7->autogen) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.7->autogen) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.7->autogen) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.7->autogen) (0.4.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.7->autogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.7->autogen) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.7->autogen) (2024.11.6)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.34.1->autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (8.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2==0.9.7->autogen) (3.4.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.7.2->autogen-agentchat>=0.6.4->pyautogen) (3.23.0)\n",
      "Downloading autogen-0.9.7-py3-none-any.whl (13 kB)\n",
      "Downloading ag2-0.9.7-py3-none-any.whl (860 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m860.4/860.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: diskcache, docker, asyncer, ag2, autogen\n",
      "Successfully installed ag2-0.9.7 asyncer-0.0.8 autogen-0.9.7 diskcache-5.6.3 docker-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogen python-dotenv autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzDWyVQ0TjVs",
    "outputId": "251925ff-0169-446b-b67f-700b5c314361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P5bJPixVTsxx"
   },
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"gpt-4o-mini\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXJiNR0T_12"
   },
   "source": [
    "## Define single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3QfV68YTTwrL"
   },
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "343g9tRcUFrF"
   },
   "outputs": [],
   "source": [
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLKpN98MUQ-s",
    "outputId": "1977f559-9d65-4647-8e85-f42f3d0b835b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shCqnDmoVKW6"
   },
   "source": [
    "## Conversation between two Conversable Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D1mxMkjIUxob"
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "      \"Your name is Cathy and you are a stand-up comedian.\"\n",
    "      \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vCckhIXVpp4",
    "outputId": "f5048e3f-b096-478f-c898-05f16d7635d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Alright, let’s roll! You know, they say laughter is the best medicine. But if that's true, I must not have health insurance because my jokes are the only thing keeping me from going to the doctor! How about you? What’s your go-to joke?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Well, they say laughter is indeed the best medicine, but if that’s the case, I must be a pharmacist because I’m handing out these jokes like candy! You know what I say, if you're ever feeling down, just remember: every time you laugh, a diet soda gets its wings!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, Joe! That’s fantastic! You're handing out jokes like a pharmacist, huh? I love it! You must be the only one making people laugh and avoiding the “side effects.” And that diet soda thing? I can just see some little can of cola soaring through the sky, screaming, “I’m sweet enough already!” Keep ‘em coming! What else you got?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> TERMINATING RUN (ceaa57ad-710a-47d2-8ccf-0c0331ca39fe): Maximum turns (2) reached\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling!\",\n",
    "    max_turns=2,\n",
    "    #is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"]\n",
    "    summary_method = \"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCYWGdOYV4MX",
    "outputId": "8dcf7868-c6c2-4cae-8e80-f27e9eb33698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling!\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe! Alright, let’s roll! You know, they say laughter is the '\n",
      "             \"best medicine. But if that's true, I must not have health \"\n",
      "             'insurance because my jokes are the only thing keeping me from '\n",
      "             'going to the doctor! How about you? What’s your go-to joke?',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': 'Well, they say laughter is indeed the best medicine, but if '\n",
      "             'that’s the case, I must be a pharmacist because I’m handing out '\n",
      "             \"these jokes like candy! You know what I say, if you're ever \"\n",
      "             'feeling down, just remember: every time you laugh, a diet soda '\n",
      "             'gets its wings!',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Haha, Joe! That’s fantastic! You're handing out jokes like a \"\n",
      "             'pharmacist, huh? I love it! You must be the only one making '\n",
      "             'people laugh and avoiding the “side effects.” And that diet soda '\n",
      "             'thing? I can just see some little can of cola soaring through '\n",
      "             'the sky, screaming, “I’m sweet enough already!” Keep ‘em coming! '\n",
      "             'What else you got?',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'}]\n",
      "{'usage_excluding_cached_inference': {'gpt-4o-mini-2024-07-18': {'completion_tokens': 468,\n",
      "                                                                 'cost': 0.00037814999999999995,\n",
      "                                                                 'prompt_tokens': 649,\n",
      "                                                                 'total_tokens': 1117},\n",
      "                                      'total_cost': 0.00037814999999999995},\n",
      " 'usage_including_cached_inference': {'gpt-4o-mini-2024-07-18': {'completion_tokens': 468,\n",
      "                                                                 'cost': 0.00037814999999999995,\n",
      "                                                                 'prompt_tokens': 649,\n",
      "                                                                 'total_tokens': 1117},\n",
      "                                      'total_cost': 0.00037814999999999995}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(chat_result.chat_history)\n",
    "pprint.pprint(chat_result.cost)\n",
    "pprint.pprint(chat_result.summary) #summary based on above settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwPUWB7OW6kP"
   },
   "source": [
    "## Using of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UL1w4_C5WEMw"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "def calculator(a:int, b:int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "  \"\"\"A simple calculator tool\"\"\"\n",
    "  if operator == \"+\":\n",
    "      return a + b\n",
    "  elif operator == \"-\":\n",
    "      return a - b\n",
    "  else:\n",
    "    raise ValueError(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Th2TWxFvXmC2"
   },
   "outputs": [],
   "source": [
    "math_expert_agent = ConversableAgent(\n",
    "    name=\"MathExpert\",\n",
    "    system_message=\n",
    "      \"You are very good at math \"\n",
    "      \"and you help users to solve thei math problems.\",\n",
    "    llm_config=llm_config,\n",
    "    function_map={\"calculator\": calculator},\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLNbL4oIX5nr",
    "outputId": "11337a23-c408-4ac3-e8d6-d83a3311bc70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.tools.tool.Tool at 0x7fb7855ea290>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_expert_agent.register_for_llm(name=\"calculator\", description=\"A tool to make math operations\")(calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "D2G_IeNiYBSW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "reply = math_expert_agent.generate_reply(\n",
    "    messages=[{\"content\":\"What is 2+2?\", \"role\" : \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65pviLs7Ym3j"
   },
   "source": [
    "## Build a team of Agents (sketch)\n",
    "\n",
    "**UserProxy**: to allow the user to comment on the report and ask the writer to refine it\n",
    "\n",
    "**Planner**: to determine relevant info needed to complete the task\n",
    "\n",
    "**Engineer**: to write code using the defined plan by the planner\n",
    "\n",
    "**Executor**: to execute the code written by the engineer\n",
    "\n",
    "**Writer**: to write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "U-G08AvnYsm8"
   },
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VmrHygO9YRS0"
   },
   "outputs": [],
   "source": [
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"user_proxy\",\n",
    "    system_message=\"Give the task and send instrctions to writer to refine the blog post\",\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"ALWAYS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAH_zYpNZ8zl"
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "irKUdP1HZ-Jq"
   },
   "outputs": [],
   "source": [
    "grouptchat = autogen.GroupChat(\n",
    "    agents=[user_proxy],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "h6_mIN-UaGPu"
   },
   "outputs": [],
   "source": [
    "#to determinate which agent should be involved\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=grouptchat,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYWvb0YoaM_6"
   },
   "outputs": [],
   "source": [
    "task = \"<Define a task>\"\n",
    "\n",
    "groupchat_result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4pa717UabIx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMciMORAauGo2zbLvlk+aTE",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
