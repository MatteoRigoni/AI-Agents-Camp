{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edf8289",
   "metadata": {},
   "source": [
    "# Text Classification Finetuning\n",
    "\n",
    "This curated notebook demonstrates text classification finetuning.\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Tutorial\n",
    "3. Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning for Text Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MPtKLEvHddB"
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "!pip uninstall -y sentence-transformers transformers tokenizers huggingface_hub accelerate safetensors torch torchvision torchaudio\n",
    "\n",
    "!pip install -U pip\n",
    "\n",
    "# PyTorch CPU\n",
    "!pip install \"torch==2.3.1\" \"torchvision==0.18.1\" --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# Stack HF + ST allineato\n",
    "!pip install \"transformers==4.45.2\" \"sentence-transformers==3.0.1\" \"datasets>=2.20\" \"accelerate>=0.33\" \"safetensors>=0.4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zhb9bC6yE4RJ"
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, evaluation, losses\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ro3ZM4_fE9nj"
   },
   "outputs": [],
   "source": [
    "#Configuration of model choosen for training\n",
    "model_checkpoint = \"dbmdz/bert-base-italian-uncased\"\n",
    "word_embedding_model = models.Transformer(model_checkpoint)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4bcBbT_F2mO"
   },
   "outputs": [],
   "source": [
    "#Dataset loading\n",
    "dataset_train = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"train\")\n",
    "dataset_test = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"test\")\n",
    "\n",
    "print(\"train size: \", dataset_train.shape)\n",
    "print(\"test size: \", dataset_test.shape)\n",
    "print(\"Esempio del dataset: \", dataset_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTSCr37jGxAy"
   },
   "outputs": [],
   "source": [
    "#Preprocessing of dataset to have format compatible with Sentence Transofrmers\n",
    "train_samples = []\n",
    "for i in range(len(dataset_train)):\n",
    "    example = dataset_train[i]\n",
    "    train_samples.append(\n",
    "        InputExample(texts=[example['sentence1'], example['sentence2']],  #two sentences to compare\n",
    "        label=float(example[\"similarity_score\"]) / 5.0)\n",
    "    )\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rR_-In-KIQ1"
   },
   "outputs": [],
   "source": [
    "#Configuring evaluator of similarity between sentences to check performance on test dataset\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(\n",
    "    dataset_test['sentence1'],\n",
    "    dataset_test['sentence2'],\n",
    "    [x / 5.0 for x in dataset_test['similarity_score']],\n",
    "    main_similarity=evaluation.SimilarityFunction.COSINE,\n",
    "    write_csv=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Cw3aKa1Ko-H"
   },
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "num_epochs=10\n",
    "evaluation_steps=500\n",
    "warmup_steps = int(len(train_dataloader)*num_epochs * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txuI9uMKM0vN"
   },
   "outputs": [],
   "source": [
    "# TODO: describe cell\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from transformers import logging\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9Ww9eyiK6o_"
   },
   "outputs": [],
   "source": [
    "#Training process\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "model.save(\"my-sentence-transforer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vg97Yfy7LjaL"
   },
   "outputs": [],
   "source": [
    "#Sharing of the model on HugguingFace\n",
    "\"\"\"\n",
    "from huggingface_hub import login\n",
    "login('token')\n",
    "model.save_to_hub(\"my-sentence-transforer\", organization='myOrg', train_datasets=[stsb_multi_mt])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4A-tRYnNZQ4"
   },
   "outputs": [],
   "source": [
    "#Unit test of the model\n",
    "sentences = [\"Una ragazza si pettina\", \"Una ragazza si sta spazzolando\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(\"Sentence embeddings:\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptwjCAd_OgF9"
   },
   "outputs": [],
   "source": [
    "#Complete test\n",
    "sentences = [\n",
    "    \"Una ragazza legge un libro\",\n",
    "    \"Una donna legge un romanzo\",\n",
    "    \"Un uomo cammina per strada\"\n",
    "    \"Una persona legge un saggio\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Display similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(similarity_matrix, columns=sentences, index=sentences)\n",
    "print(\"Similarity matrix:\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1U3AAWI9pyC4KGuJHM6pq",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
