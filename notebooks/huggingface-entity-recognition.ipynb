{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNX0JHKNPKiA3uhvckQZKVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entity Recognition with Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Vk0YPdSjPU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets<3.0 torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sA8quPBPSqN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading model and relative tokenizer\n",
        "MODEL_NAME = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "N9S2VluTTPEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating NER pipeline\n",
        "ner_pipeline = pipeline(task=\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
      ],
      "metadata": {
        "id": "sZo0-x_HTdfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper methods\n",
        "def analyze_text(text):\n",
        "  \"\"\"\n",
        "  Perform NER analysis on a text\n",
        "  Returs dataframe with results\n",
        "  \"\"\"\n",
        "  ner_results = ner_pipeline(text)\n",
        "  df = pd.DataFrame(ner_results)\n",
        "  df = df.rename(columns={\"word\": \"Parola\", \"entity_group\": \"Tipo\", \"score\": \"Confidenza\"})\n",
        "  return df\n",
        "\n",
        "def analyze_batch(sentences):\n",
        "  \"\"\"\n",
        "  Perform NER analysis on a batch of sentences\n",
        "  Returs dataframe with results\n",
        "  \"\"\"\n",
        "  batch_results = ner_pipeline(sentences)\n",
        "  results = []\n",
        "  for i, sentence_results in enumerate(batch_results):\n",
        "    for entity in sentence_results:\n",
        "      results.append({\n",
        "          \"Frase\": sentences[i],\n",
        "          \"Parola\": entity[\"word\"],\n",
        "          \"Tipo\": entity[\"entity_group\"],\n",
        "          \"Confidenza\": entity[\"score\"]\n",
        "      })\n",
        "  return pd.DataFrame(results)\n",
        "\n",
        "def save_results_to_csv(df, filename):\n",
        "  \"\"\"\n",
        "  Save results to CSV file\n",
        "  \"\"\"\n",
        "  df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "uOKNIBu7Ua9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test (single)\n",
        "text = \"Juventus is an italian football team based in Turin\"\n",
        "\n",
        "#Analysis\n",
        "df_results = analyze_text(text)\n",
        "print(df_results)\n",
        "\n",
        "#Display recognized entities\n",
        "unique_entities = df_results[\"Tipo\"].unique()\n",
        "print(unique_entities)"
      ],
      "metadata": {
        "id": "iIKYyMV8WMlg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
